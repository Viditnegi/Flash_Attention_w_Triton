# Flash attention with triton.
Implementation of the Flash Attention 2 algorithm, based on the code published by OpenAI's team at Fused Attention.

ref. https://triton-lang.org/main/getting-started/tutorials/06-fused-attention.html
